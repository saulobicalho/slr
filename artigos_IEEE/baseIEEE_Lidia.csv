Document Title,Authors,Author Affiliations,Publication Title,Publication_Year,Abstract,PDF Link,Author Keywords,IEEE Terms,Publisher,Document Identifier,CritÈrio de Exclus„o,Status Etapa 1
The Role of OAIS Representation Information in the Digital Curation of Crystallography Data,M. Patel; S. Coles; D. Giaretta; S. Rankin; B. McIlwrath,NA; NA; NA; NA; NA,2009 Fifth IEEE International Conference on e-Science,2009,"Reusable high quality data are emerging as the raw material of contemporary e-science. Large volumes of scientific data are now ¬øborn-digital¬ø and need to be curated to facilitate use and reuse. Representation Information (RI) as defined by the OAIS Reference Model is increasingly recognised as being vital to the long term curation and preservation of meaningful and reliable digital data. This paper is concerned with an investigation of RI for crystallography data and its role in the curation, maintenance and management of such data. We describe how the explicit recording of relevant RI can facilitate long term access and maintain intelligibility of the Crystallographic Information File format (a critical file format in the crystallography domain).",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5380876,Digital curation;Preservation;Crystallography data;Representation Information;OAIS Reference Model,Crystallography;Raw materials;Maintenance;Hardware;Materials science and technology;Councils;Instruments;Memory;Grid computing;Data analysis,IEEE,IEEE Conferences,,
Considerations for model curation in model-centric systems engineering,L. Reymondet; A. M. Ross; D. H. Rhodes,"Systems Engineering Advancement Research Initiative, Massachusetts Institute of Technology, Cambridge, MA 02139; Systems Engineering Advancement Research Initiative, Massachusetts Institute of Technology, Cambridge, MA 02139; Systems Engineering Advancement Research Initiative, Massachusetts Institute of Technology, Cambridge, MA 02139",2016 Annual IEEE Systems Conference (SysCon),2016,"Contemporary systems are often highly complex sociotechnical systems that require models to help system engineers with sense-making and decision-making. The systems community has developed and instantiated many modeling approaches, practices, formal languages and toolsets, which are all areas of progress. If models and their instantiations could be managed as assets, documented, archived, protected, retrieved and re-used as such, modeling and analysis tasks would likely gain in quality and timeliness. This paper asks the question ""What would a curator need to know about models or their instantiations to provide a model curation function""? Considerations of the activities and body of knowledge associated with curation of models are presented. The potential usefulness of a curated system modeling approach is illustrated in an example.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490560,socio-technical systems;systems of systems;models;model-centric;model curation,Computational modeling;Analytical models;Organizations;Data models;Atmospheric modeling,IEEE,IEEE Conferences,,
The Architecture and Design of a Community-Based Cloud Platform for Curating Big Data,S. K. Sowe; K. Zettsu,NA; NA,2013 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery,2013,"The digital universe is exponentially producing unprecedented volume of data that has brought benefits, as well as fundamental challenges for the research community. This trend is inherently exciting for the development and deployment of cloud platforms to support research communities curate data. The excitements stems from the fact that researchers can now have more access and discover more value in data, establish relationships between bits and pieces of information from many types of data, and collaborate with a diverse community of researchers from various domains. Technically, however, platform providers must design their infrastructure in such a way that users can easily search, find, share, and seamlessly collaborate. In this paper, we present the architecture and design of a cloud platform and describe how a community of disaster response scientists could use the platform to curate data. Motivation for developing the platform, lessons learnt in overcoming some challenges associated with collaborative and cooperative cloud environments, and future research directions are also presented. The contribution of this research is in the field of cloud infrastructure for supporting data curation activities, and the sustenance of research communities for the utilization of information assets and cyber technologies.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6685676,Cloud computing;Big data;Data curation;Scientific communities;Collaborative environments,Communities;Information management;Data handling;Data storage systems;Clouds;Information services;Collaboration,IEEE,IEEE Conferences,,
"Live demonstration: Automated data acquisition and digital curation platform for enhancing research precision, productivity and reproducibility",Y. Gtat; S. Parsnejad; A. J. Mason,"Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA",2017 IEEE International Symposium on Circuits and Systems (ISCAS),2017,"A highly flexible software platform for automated data acquisition, production of research objects with data provenance and curation of experiment results throughout the life cycle of the data will be introduced and demonstrated along with a custom miniaturized electrochemical sensor system. The software platform, called eGor, allows users to define test procedures and components through a user friendly access point. Specific experiment definitions can be saved for later use or recalled as templates for modified tests. The user can then remotely execute the test on any connected physical experiment workbench in a real lab environment. Once the test is complete, eGor will capture an organized and metadata-rich research object that includes the raw test data, detailed definition of the test setup, and all procedural elements of the executed test such as the timings, test successions, device conditions, etc. The generated research object are stored for subsequent curating or data analysis, and any access or treatment of the results is automatically recorded to maintain data provenance. eGor also allows stored research objects to be shared with collaborators or provided to any institution that would be interested in reproducing the same results. The results may be inspected at various levels of detail, annotated and compared with other research objects. Thus, eGor would help researchers increase their confidence in their results and conclusions and promote improved research reproducibility. During this demonstrations the users will be allowed to interact with hardware blocks that mimic a simple lab setup, and the users may define, schedule and perform tests using these devices and save their test results as research objects.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8050711,,,IEEE,IEEE Conferences,,
Entity Resolution in the Web of Data,V. Christophides; V. Efthymiou; K. Stefanidis,"Computer Science at the University of Crete.; University of Crete and a member of the Information Systems Laboratory of the Institute of Computer Science at FORTH.; ICS-FORTH, Greece.",Entity Resolution in the Web of Data,2015,"In recent years, several knowledge bases have been built to enable large-scale knowledge sharing, but also an entity-centric Web search, mixing both structured data and text querying. These knowledge bases offer machine-readable descriptions of real-world entities, e.g., persons, places, published on the Web as Linked Data. However, due to the different information extraction tools and curation policies employed by knowledge bases, multiple, complementary and sometimes conflicting descriptions of the same real-world entities may be provided. Entity resolution aims to identify different descriptions that refer to the same entity appearing either within or across knowledge bases. The objective of this book is to present the new entity resolution challenges stemming from the openness of the Web of data in describing entities by an unbounded number of knowledge bases, the semantic and structural diversity of the descriptions provided across domains even for the same real-world entities, as well as the autonomy of knowledge bases in terms of adopted processes for creating and curating entity descriptions. The scale, diversity, and graph structuring of entity descriptions in the Web of data essentially challenge how two descriptions can be effectively compared for similarity, but also how resolution algorithms can efficiently avoid examining pairwise all descriptions. The book covers a wide spectrum of entity resolution issues at the Web scale, including basic concepts and data structures, main resolution tasks and workflows, as well as state-of-the-art algorithmic techniques and experimental trade-offs.",https://ieeexplore.ieee.org,entity resolution;Web of data,,Morgan & Claypool,,,
Towards a Hybrid Human-Computer Scientific Information Extraction Pipeline,R. B. Tchoua; K. Chard; D. J. Audus; L. T. Ward; J. Lequieu; J. J. De Pablo; I. T. Foster,NA; NA; NA; NA; NA; NA; NA,2017 IEEE 13th International Conference on e-Science (e-Science),2017,"The emerging field of materials informatics has the potential to greatly reduce time-to-market and development costs for new materials. The success of such efforts hinges on access to large, high-quality databases of material properties. However, many such data are only to be found encoded in text within esoteric scientific articles, a situation that makes automated extraction difficult and manual extraction time-consuming and error-prone. To address this challenge, we present a hybrid Information Extraction (IE) pipeline to improve the machine-human partnership with respect to extraction quality and person-hours, through a combination of rule-based, machine learning, and crowdsourcing approaches. Our goal is to leverage computer and human strengths to alleviate the burden on human curators by automating initial extraction tasks before prioritizing and assigning specialized curation tasks to humans with different levels of training: using non-experts for straightforward tasks such as validation of higher accuracy results (e.g., completing partial facts) and domain experts for low-certainty results (e.g., reviewing specialized compound labels). To validate our approaches, we focus on the task of extracting the glass transition temperature of polymers from published articles. Applying our approaches to 6 090 articles, we have so far extracted 259 refined data values. We project that this number will grow considerably as we tune our methods and process more articles, to exceed that found in standard, expert-curated polymer data handbooks while also being easier to keep up-to-date. The freely available data can be found on our Polymer Properties Predictor and Database website at http://pppdb.uchicago.edu.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8109128,Information Extraction;Crowdsourcing;Machine Learning;Polymers;Glass transition,Plastics;Pipelines;Data mining;Databases;Crowdsourcing;Polymers,IEEE,IEEE Conferences,,
Data curation with a focus on reuse,M. Esteva; S. Sweat; R. McLay; W. Xu; S. Kulasekaran,"Texas Advanced Computing Center, Austin, Texas; University of Texas at Austin, Austin, Texas; Texas Advanced Computing Center, Austin, Texas; Texas Advanced Computing Center, Austin, Texas; Texas Advanced Computing Center, Austin, Texas",2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL),2016,"A dataset from the field of High Performance Computing (HPC) was curated with the focus on facilitating its reuse and to appeal to a broader audience beyond HPC specialists. At an early stage in the research project, the curators gathered requirements from prospective users of the dataset, focusing on how and for which research projects they would reuse the data. Users needs informed which curation tasks to conduct, which included: adding more information elements to the dataset to expand its content scope; removing personal information; and, packaging the data in a size, a format, and at a frequency of delivery that are convenient for access and analysis purposes. The curation tasks are embedded in the software that produces the data, and are implemented as an automated workflow that spans various HPC resources, in which the dataset is generated, processed and stored and the Texas ScholarWorks institutional repository, through which the data is published. Within this distributed architecture, the integrated data creation and curation workflow complies with long-term preservation requirements, and is the first one implemented as a collaboration between the supercomputing center where the data is created on ongoing basis, and the University Libraries at UT Austin where it is published. The targeted curation strategy included the design of proof of concept data analyses to evaluate if the curated data met the reuse scenarios proposed by users. The results suggest that the dataset is understandable, and that researchers can use it to answer some of the research questions they posed. Results also pointed to specific elements of the curation strategy that had to be improved and disclosed the difficulties involved in breaking data to new users.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559563,Data curation;high performance computing;distributed collections architecture;data publishing and reuse,Software;Supercomputers;Distributed databases;Libraries;Metadata;High performance computing,IEEE,IEEE Conferences,,
PhotoSpread: A Spreadsheet for Managing Photos,H. Garcia-Molina,"Department of Computer Science, Stanford University, Stanford, CA 94305, USA. hector@cs.stanford.edu",2008 IEEE 24th International Conference on Data Engineering,2008,"The goal of the BioACT Project at Stanford is to help biodiversity researchers Acquire digital materials in the field, manage these online holdings (Curate), and Transfer the knowledge (or disseminate) to other researchers, museums, and the public. We are developing three sets of tools: (i) tools for speedy data entry and small-group collaboration in the field, (ii) tools for large scale collaboration in distributed collection curation, and (iii) tools for semidirected search and browsing of digital biodiversity materials.Currently, the biologists use spreadsheets to analyze the photos. Each photograph is represented by a row in the spreadsheet. One column gives the file name where the photo is stored, and the other columns give the metadata (date, species, etc.). Once the data is in the spreadsheet, they can select and group photos of interest and compute relevant statistics. In this paper, we describe Photospread in more detail. We discuss the supported formula language, and we describe how drag-and-drop actions work. We also compare Photospread to other photo browsing and analysis tools.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4497405,,Animals;Biology computing;Displays;Biodiversity;Collaborative tools;Temperature;Biological materials;Cameras;Statistics;Computer science,IEEE,IEEE Conferences,,
Autonomic Curation of Crowdsourced Knowledge: The Case of Career Data Management,A. Patelli; P. Lewis; H. Wang; I. Nabney; D. Bennett; R. Lucas; A. Cole,NA; NA; NA; NA; NA; NA; NA,2016 International Conference on Cloud and Autonomic Computing (ICCAC),2016,"Automatically curating knowledge that is available online is a pressing necessity, given the exponential increase in the volume of data published over the web. However, the solutions presently available are yet to reach the same level of support quality provided by human curators. This is mainly due to the fact that digital database managers do not take the expertise of the interested community into account nor exploit the underlying connections between knowledge pieces when processing user queries. We propose an approach to bridge the gap between automated curation and the one provided by human experts and implement it in the field of career data management. The resulting platform, Aviator, is based on an ontology powered autonomic manager which produces complete, intuitive and relevant answers to career related queries, in a time effective manner. We provide numeric and use case based evidence to support these research claims.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7774959,,Engineering profession;Ontologies;Databases;Medical diagnostic imaging;Libraries;Search engines;Visualization,IEEE,IEEE Conferences,,
4CeeD: Real-Time Data Acquisition and Analysis Framework for Material-Related Cyber-Physical Environments,P. Nguyen; S. Konstanty; T. Nicholson; T. O‚ÄôBrien; A. Schwartz-Duval; T. Spila; K. Nahrstedt; R. H. Campbell; I. Gupta; M. Chan; K. Mchenry; N. Paquin,NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA,"2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)",2017,"In this paper, we present a data acquisition and analysis framework for materials-to-devices processes, named 4CeeD, that focuses on the immense potential of capturing, accurately curating, correlating, and coordinating materials-to-devices digital data in a real-time and trusted manner before fully archiving and publishing them for wide access and sharing. In particular, 4CeeD consists of novel services: a curation service for collecting data from microscopes and fabrication instruments, curating, and wrapping of data with extensive metadata in real-time and in a trusted manner, and a cloud-based coordination service for storing data, extracting meta-data, analyzing and finding correlations among the data. Our evaluation results show that our novel cloud framework can help researchers significantly save time and cost spent on experiments, and is efficient in dealing with high-volume and fast-changing workload of heterogeneous types of experimental data.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7973684,cyber-physical systems;cloud computing;resource management,Fabrication;Scanning electron microscopy;Data models;Databases;Real-time systems,IEEE,IEEE Conferences,,
Data and Software Preservation for Open Science (DASPOS),M. D. Hildreth,"Physics Department, University of Notre Dame Notre Dame, IN, USA",2014 IEEE 30th International Conference on Data Engineering Workshops,2014,"Data and Software Preservation for Open Science (DASPOS), represents a first attempt to establish a formal collaboration tying together physicists from the CMS and ATLAS experiments at the LHC and the Tevatron experiments with experts in digital curation, heterogeneous high-throughput storage systems, large-scale computing systems, and grid access and infrastructure. Recently funded by the National Science Foundation, the project is organizing multiple workshops aimed at understanding use cases for data, software, and knowledge preservation in High Energy Physics and other scientific disciplines, including BioInformatics and Astrophysics. The goal of this project is the technical development and specification of an architecture for curating HEP data and software to the point where the repetition of a physics analysis using only the archived data, software, and analysis description is possible. The novelty of this effort is this holistic approach, where not only data but also software and frameworks necessary to use the data are part of the preservation effort, making it true ‚Äúphysics preservation‚Äù rather than merely data preservation.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6818318,,Software;Educational institutions;Physics;Conferences;Data models;Semantics;Computer architecture,IEEE,IEEE Conferences,,
Towards Sustainable Curation and Preservation: The SEAD Project's Data Services Approach,J. Myers; M. Hedstrom; D. Akmon; S. Payette; B. A. Plale; I. Kouper; S. McCaulay; R. McDonald; I. Suriarachchi; A. Varadharaju; P. Kumar; M. Elag; J. Lee; R. Kooper; L. Marini,NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA,2015 IEEE 11th International Conference on e-Science,2015,"When the effort to curate and preserve data is made at the end of a project, there is little opportunity to leverage ongoing research work to reduce curation costs or conversely, to leverage curation efforts to improve research productivity. In the Sustainable Environment Actionable Data (SEAD) project, we have envisioned a more active approach to data curation and preservation in which these processes occur in parallel with research and generate sufficient short and long-term return on researcher investments for self-interest to drive their adoption. In this paper, we describe the conceptual framework motivating the SEAD project and the suite of data services we have developed and deployed as an initial implementation of this approach. Use cases in which these services can reduce curation effort and aid ongoing research are highlighted and, based on our experience to date, we identify some key architectural features of our approach as well as open challenges to fully realizing the value of this approach in the broad ecosystem of cyberinfrastructure.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7304332,data curation;data preservation;research productivity;semantic web;content management;web services,Metadata;Data mining;File systems;Web services;Resource description framework;Biomedical imaging;Databases,IEEE,IEEE Conferences,,
