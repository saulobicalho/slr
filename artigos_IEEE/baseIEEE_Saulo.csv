Document Title,Authors,Author Affiliations,Publication Title,Publication_Year,Abstract,PDF Link,Author Keywords,IEEE Terms,Publisher,Document Identifier,CritÈrio de Exclus„o,Status Etapa 1,
The Role of OAIS Representation Information in the Digital Curation of Crystallography Data,M. Patel, S. Coles, D. Giaretta, S. Rankin, B. McIlwrath,NA, NA, NA, NA, NA,5,Excluido,
Considerations for model curation in model-centric systems engineering,L. Reymondet, A. M. Ross, D. H. Rhodes,"Systems Engineering Advancement Research Initiative, Massachusetts Institute of Technology, Cambridge, MA 02139; Systems Engineering Advancement Research Initiative, Massachusetts Institute of Technology, Cambridge, MA 02139; Systems Engineering Advancement Research Initiative, Massachusetts Institute of Technology, Cambridge, MA 02139",2016 Annual IEEE Systems Conference (SysCon),2016,"Contemporary systems are often highly complex sociotechnical systems that require models to help system engineers with sense-making and decision-making. The systems community has developed and instantiated many modeling approaches, practices, formal languages and toolsets, which are all areas of progress. If models and their instantiations could be managed as assets, documented, archived, protected, retrieved and re-used as such, modeling and analysis tasks would likely gain in quality and timeliness. This paper asks the question ""What would a curator need to know about models or their instantiations to provide a model curation function""? Considerations of the activities and body of knowledge associated with curation of models are presented. The potential usefulness of a curated system modeling approach is illustrated in an example.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490560,socio-technical systems,systems of systems,,Aceito,
The Architecture and Design of a Community-Based Cloud Platform for Curating Big Data,S. K. Sowe, K. Zettsu,NA, NA,2013 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery,2013,"The digital universe is exponentially producing unprecedented volume of data that has brought benefits, as well as fundamental challenges for the research community. This trend is inherently exciting for the development and deployment of cloud platforms to support research communities curate data. The excitements stems from the fact that researchers can now have more access and discover more value in data, establish relationships between bits and pieces of information from many types of data, and collaborate with a diverse community of researchers from various domains. Technically, however, platform providers must design their infrastructure in such a way that users can easily search, find, share, and seamlessly collaborate. In this paper, we present the architecture and design of a cloud platform and describe how a community of disaster response scientists could use the platform to curate data. Motivation for developing the platform, lessons learnt in overcoming some challenges associated with collaborative and cooperative cloud environments, and future research directions are also presented. The contribution of this research is in the field of cloud infrastructure for supporting data curation activities, and the sustenance of research communities for the utilization of information assets and cyber technologies.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6685676,Cloud computing,Big data,5,Excluido,
"Live demonstration: Automated data acquisition and digital curation platform for enhancing research precision, productivity and reproducibility",Y. Gtat, S. Parsnejad, A. J. Mason,"Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA",2017 IEEE International Symposium on Circuits and Systems (ISCAS),2017,"A highly flexible software platform for automated data acquisition, production of research objects with data provenance and curation of experiment results throughout the life cycle of the data will be introduced and demonstrated along with a custom miniaturized electrochemical sensor system. The software platform, called eGor, allows users to define test procedures and components through a user friendly access point. Specific experiment definitions can be saved for later use or recalled as templates for modified tests. The user can then remotely execute the test on any connected physical experiment workbench in a real lab environment. Once the test is complete, eGor will capture an organized and metadata-rich research object that includes the raw test data, detailed definition of the test setup, and all procedural elements of the executed test such as the timings, test successions, device conditions, etc. The generated research object are stored for subsequent curating or data analysis, and any access or treatment of the results is automatically recorded to maintain data provenance. eGor also allows stored research objects to be shared with collaborators or provided to any institution that would be interested in reproducing the same results. The results may be inspected at various levels of detail, annotated and compared with other research objects. Thus, eGor would help researchers increase their confidence in their results and conclusions and promote improved research reproducibility. During this demonstrations the users will be allowed to interact with hardware blocks that mimic a simple lab setup, and the users may define, schedule and perform tests using these devices and save their test results as research objects.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8050711,,,2,Excluido,
Entity Resolution in the Web of Data,V. Christophides, V. Efthymiou, K. Stefanidis,"Computer Science at the University of Crete.; University of Crete and a member of the Information Systems Laboratory of the Institute of Computer Science at FORTH.; ICS-FORTH, Greece.",Entity Resolution in the Web of Data,2015,"In recent years, several knowledge bases have been built to enable large-scale knowledge sharing, but also an entity-centric Web search, mixing both structured data and text querying. These knowledge bases offer machine-readable descriptions of real-world entities, e.g., persons, places, published on the Web as Linked Data. However, due to the different information extraction tools and curation policies employed by knowledge bases, multiple, complementary and sometimes conflicting descriptions of the same real-world entities may be provided. Entity resolution aims to identify different descriptions that refer to the same entity appearing either within or across knowledge bases. The objective of this book is to present the new entity resolution challenges stemming from the openness of the Web of data in describing entities by an unbounded number of knowledge bases, the semantic and structural diversity of the descriptions provided across domains even for the same real-world entities, as well as the autonomy of knowledge bases in terms of adopted processes for creating and curating entity descriptions. The scale, diversity, and graph structuring of entity descriptions in the Web of data essentially challenge how two descriptions can be effectively compared for similarity, but also how resolution algorithms can efficiently avoid examining pairwise all descriptions. The book covers a wide spectrum of entity resolution issues at the Web scale, including basic concepts and data structures, main resolution tasks and workflows, as well as state-of-the-art algorithmic techniques and experimental trade-offs.",https://ieeexplore.ieee.org,entity resolution,Web of data,2,Excluido,"obs o pdf n„o foi baixado, È livro"
Towards a Hybrid Human-Computer Scientific Information Extraction Pipeline,R. B. Tchoua, K. Chard, D. J. Audus, L. T. Ward, J. Lequieu, J. J. De Pablo, I. T. Foster,NA, NA, NA,,Aceito,
Data curation with a focus on reuse,M. Esteva, S. Sweat, R. McLay, W. Xu, S. Kulasekaran,"Texas Advanced Computing Center, Austin, Texas; University of Texas at Austin, Austin, Texas; Texas Advanced Computing Center, Austin, Texas; Texas Advanced Computing Center, Austin, Texas; Texas Advanced Computing Center, Austin, Texas",2016 IEEE/ACM Joint Conference on Digital Libraries (JCDL),2016,"A dataset from the field of High Performance Computing (HPC) was curated with the focus on facilitating its reuse and to appeal to a broader audience beyond HPC specialists. At an early stage in the research project, the curators gathered requirements from prospective users of the dataset, focusing on how and for which research projects they would reuse the data. Users needs informed which curation tasks to conduct, which included: adding more information elements to the dataset to expand its content scope; removing personal information; and, packaging the data in a size, a format, and at a frequency of delivery that are convenient for access and analysis purposes. The curation tasks are embedded in the software that produces the data, and are implemented as an automated workflow that spans various HPC resources, in which the dataset is generated, processed and stored and the Texas ScholarWorks institutional repository, through which the data is published. Within this distributed architecture, the integrated data creation and curation workflow complies with long-term preservation requirements, and is the first one implemented as a collaboration between the supercomputing center where the data is created on ongoing basis, and the University Libraries at UT Austin where it is published. The targeted curation strategy included the design of proof of concept data analyses to evaluate if the curated data met the reuse scenarios proposed by users. The results suggest that the dataset is understandable, and that researchers can use it to answer some of the research questions they posed. Results also pointed to specific elements of the curation strategy that had to be improved and disclosed the difficulties involved in breaking data to new users.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7559563,,Aceito,
PhotoSpread: A Spreadsheet for Managing Photos,H. Garcia-Molina,"Department of Computer Science, Stanford University, Stanford, CA 94305, USA. hector@cs.stanford.edu",2008 IEEE 24th International Conference on Data Engineering,2008,"The goal of the BioACT Project at Stanford is to help biodiversity researchers Acquire digital materials in the field, manage these online holdings (Curate), and Transfer the knowledge (or disseminate) to other researchers, museums, and the public. We are developing three sets of tools: (i) tools for speedy data entry and small-group collaboration in the field, (ii) tools for large scale collaboration in distributed collection curation, and (iii) tools for semidirected search and browsing of digital biodiversity materials.Currently, the biologists use spreadsheets to analyze the photos. Each photograph is represented by a row in the spreadsheet. One column gives the file name where the photo is stored, and the other columns give the metadata (date, species, etc.). Once the data is in the spreadsheet, they can select and group photos of interest and compute relevant statistics. In this paper, we describe Photospread in more detail. We discuss the supported formula language, and we describe how drag-and-drop actions work. We also compare Photospread to other photo browsing and analysis tools.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4497405,,Animals,Biology computing,Displays,"5,2",Excluido,
Autonomic Curation of Crowdsourced Knowledge: The Case of Career Data Management,A. Patelli, P. Lewis, H. Wang, I. Nabney, D. Bennett, R. Lucas, A. Cole,NA, NA, NA,,Aceito,
4CeeD: Real-Time Data Acquisition and Analysis Framework for Material-Related Cyber-Physical Environments,P. Nguyen, S. Konstanty, T. Nicholson, T. O‚ÄôBrien, A. Schwartz-Duval, T. Spila, K. Nahrstedt, R. H. Campbell, I. Gupta, M. Chan,,Aceito,
Data and Software Preservation for Open Science (DASPOS),M. D. Hildreth,"Physics Department, University of Notre Dame Notre Dame, IN, USA",2014 IEEE 30th International Conference on Data Engineering Workshops,2014,"Data and Software Preservation for Open Science (DASPOS), represents a first attempt to establish a formal collaboration tying together physicists from the CMS and ATLAS experiments at the LHC and the Tevatron experiments with experts in digital curation, heterogeneous high-throughput storage systems, large-scale computing systems, and grid access and infrastructure. Recently funded by the National Science Foundation, the project is organizing multiple workshops aimed at understanding use cases for data, software, and knowledge preservation in High Energy Physics and other scientific disciplines, including BioInformatics and Astrophysics. The goal of this project is the technical development and specification of an architecture for curating HEP data and software to the point where the repetition of a physics analysis using only the archived data, software, and analysis description is possible. The novelty of this effort is this holistic approach, where not only data but also software and frameworks necessary to use the data are part of the preservation effort, making it true ‚Äúphysics preservation‚Äù rather than merely data preservation.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6818318,,Software,Educational institutions,Physics,,Aceito,
Towards Sustainable Curation and Preservation: The SEAD Project's Data Services Approach,J. Myers, M. Hedstrom, D. Akmon, S. Payette, B. A. Plale, I. Kouper, S. McCaulay, R. McDonald, I. Suriarachchi, A. Varadharaju,,Aceito,
